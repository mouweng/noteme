# 海量数据处理问题

- [教你如何迅速秒杀掉：99%的海量数据处理面试题](https://blog.csdn.net/WantFlyDaCheng/article/details/81531994)

## 一、Hash映射 + Hash_map统计 + 堆/快速/归并排序

> 1. 分治：hash取模
> 2. 处理：hash统计
> 3. 合并：堆排序/归并/快排

### 无序的数组求TopK

> 求TopK大就用最小堆；求TopK小就用最大堆；

以TopK大为例，每次和堆顶元素进行比较（堆顶就是堆的守门员）：

- 比堆顶大就替换堆顶，计算新的堆顶
- 比堆顶小就直接过滤

时间复杂度`O(N)`

### 有序的数组求TopK

> 求TopK大就用最大堆；求TopK小就用最小堆；

以TopK小为例，维护一个大小为K的最小堆，先将每个数组的第一个数入堆，每次将堆顶出堆，把这个堆顶所在数组的下一个数入堆，再重新维护堆，以此类推，重复K次这样的操作就能得到topK。

时间复杂度`O(K)`

### 例题

#### 例题1

> 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M，返回频数最高的100个词。

1. 分治：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,…x4999）中，每个文件大概是200k左右。
2. 统计：对每个小文件，采用hashmap统计文件中出现的词以及相应的频率，存入文件。
3. 合并：求出每个文件频率最高的100个词（可以用最小堆）。再合并所有文件的词（将一组各自有序的数组求TopK，采用最大堆），求得频率最高的100个词。（也可以再用一次最小堆）

#### 例题2

> 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。

1. 分治：顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件（记为a0,a1,..a9）中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。
2. 统计：找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。
3. 合并：利用快速/堆/归并排序按照出现次数进行排序，将排序好的query和对应的query_cout输出到文件中，这样得到了10个排好序的文件。最后，对这10个文件进行归并排序（内排序与外排序相结合）。

#### 例题3

> 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

hash映射（分文件） + hash_set统计（分文件逐个对比）

#### 例题4

> 怎么在海量数据中找出重复次数最多的一个？

hash映射（分文件）+ hash_map统计 + 合并求最大

#### 例题5

> 上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据？

hash映射（分文件）+ hash_map统计 + 合并用堆求前N

#### 例题6

> 1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？

- 用trie树比较好实现
- hash映射（分文件）+ hash_map统计+取出没有重复的字符串。

#### 例题7

> 500个数组，每个数组500个元素，每个数组从大到小拍好了序，求这500个数组中前500大的数

维护一个大小为500的最大堆，先将每个数组的第1个数入堆，然后最大值出堆，再进入此数所在数组的第二个数，一次类推，得到前500个最小的值。（相当于每一次将500个数组的最大值在堆中进行运算，选出最大的，重复500次）

## 二、多层划分

> 适用范围：第k大，中位数，不重复或重复的数字

基本原理及要点：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。

#### 问题

- 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。
  1. 整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域。
  2. 然后不同的区域在利用bitmap就可以直接解决了。

- 5亿个int找它们的中位数。
  1. 将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数。根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几位数刚好是中位数。
  2. 然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

## 三、Bloom filter/Bitmap

### 位图BitMap

> 位图，即位（Bit）的集合，是一种数据结构，可用于记录大量的0-1状态。通常是用来判断某个数据存不存在的。

![位图](https://cdn.jsdelivr.net/gh/mouweng/FigureBed/img/202204021323997.jpg)

#### 问题

- 已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。

  答：8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。

- 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。

  答：将bit-map扩展一下，用2bit表示一个数即可，0表示未出现，1表示出现一次，2表示出现2次及以上。

### 布隆过滤器

> 特点是高效地插入和查询，可以用来告诉你 **“某样东西一定不存在或者可能存在”**。

#### 原理

![布隆过滤器](https://cdn.jsdelivr.net/gh/mouweng/FigureBed/img/202204021304404.jpg)

- 布隆过滤器是**一个位图（BitMap）**和**多个不同的哈希函数**的组合。
- 将hash函数对应的值的位数组置`1`：
  - 查找时如果发现所有hash函数对应位都是`1`，说明可能存在
  - 查找时如果发现有hash函数对应位是`0`，则一定不存在

- 传统的布隆过滤器并不支持删除操作
- 需要根据输入元素个数n，确定位数组m的大小及hash函数个数。

#### Counting Bloom filter

- 将位数组中的每一位扩展为一个counter，从而支持了元素的删除操作。

## 四、Trie树/数据库/倒排索引

### Trie树

> 适用范围：数据量大，重复多，但是数据种类小可以放入内存

### 数据库索引

> 适用范围：大数据量的增删改查

基本原理及要点：利用数据的设计实现方法，对海量数据的增删改查进行处理。

### 倒排索引

>  适用范围：搜索引擎，关键字查询

一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。

## 五、外排序

> 适用范围：大数据的排序，去重。

基本原理及要点：外排序的归并方法，置换选择败者树原理，最优归并树。

#### 问题

- 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M，返回频数最高的100个词。

  答：这个数据具有很明显的特点，词的大小为16个字节，但是内存只有1m做hash有些不够，所以可以用外排序，内存可以当输入缓冲区使用。

## 密匙六、分布式处理之Mapreduce

>  适用范围：数据量大，但是数据种类小可以放入内存

基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约。

